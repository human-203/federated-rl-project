# Federated RL for Client Selection on Battery-Limited IoT âš¡

This project explores **Reinforcement Learning (RL)** for optimized **client selection** in **Federated Learning** environments, where IoT devices are constrained by limited battery and network bandwidth.

---

## ğŸš€ Objective
Develop and compare strategies for selecting which IoT clients participate in each federated learning round to balance:
- Model convergence speed,
- Energy efficiency,
- Communication fairness.

---

## ğŸ§  Approach Overview
We model the client selection as a **Reinforcement Learning problem**:
- **State (S):** Client battery, data size/quality, contribution history, uplink speed.  
- **Action (A):** Select K clients to train in the current round.  
- **Reward (R):** Improvement in global validation accuracy âˆ’ energy cost âˆ’ penalty for deadline misses.

**RL Agents:**  
Compare baseline strategies (Random, K-Greedy, FedCS) vs. RL-based policies such as **DQN**, **PPO**, and **Combinatorial UCB**.

---

## ğŸ§© Repository Structure
  federated-rl-project/
â”œâ”€ simulator/
â”‚ â”œâ”€ client.py # Client device logic
â”‚ â”œâ”€ server.py # Federated aggregation logic
â”‚ â”œâ”€ env.py # RL environment (Gym-compatible)
â”œâ”€ agents/
â”‚ â”œâ”€ train_dqn.py # DQN training loop
â”‚ â”œâ”€ train_ppo.py # PPO training loop
â”œâ”€ experiments/
â”‚ â”œâ”€ run_baseline.py # Random & Greedy baseline runs
â”‚ â”œâ”€ eval_policies.py # Evaluation across seeds
â”œâ”€ notebooks/
â”‚ â”œâ”€ Week2_Baselines.ipynb # Colab: baseline training
â”‚ â”œâ”€ Week3_RL_Training.ipynb# Colab: RL policy training
â”‚ â”œâ”€ Week4_Evaluation.ipynb # Colab: metrics + plots
â”œâ”€ results/ # Logs, metrics, plots, models
â”œâ”€ docs/
â”‚ â”œâ”€ report.md / slides.pdf # Final report and presentation
â”œâ”€ requirements.txt
â””â”€ README.md


---

## âš™ï¸ Installation
To set up locally:
git clone https://github.com/human-203/federated-rl-project.git
cd federated-rl-project
python3 -m venv venv
source venv/bin/activate  # on Mac/Linux
pip install -r requirements.txt

## To run a simple simulation:
python experiments/run_baseline.py
